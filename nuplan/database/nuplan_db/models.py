"""
nuplandb models, schema version: 3.0, code generated by schema_gen.py.
DO NOT MODIFY THIS FILE UNLESS YOU KNOW WHAT YOU ARE DOING!
"""
from __future__ import annotations  # postpone evaluation of annotations

import logging
import os
import os.path as osp
from typing import Any, BinaryIO, Dict, List, Optional, Set

import cv2
import matplotlib.pyplot as plt
import numpy as np
import numpy.typing as npt
import PIL
from matplotlib.axes import Axes
from nuplan.database.common import data_types, sql_types
from nuplan.database.common.utils import simple_repr
from nuplan.database.nuplan_db.frame import Frame
from nuplan.database.nuplan_db.utils import (
    get_boxes,
)
from nuplan.database.utils.boxes.box3d import Box3D, BoxVisibility, box_in_image
from pyquaternion import Quaternion
from scipy import ndimage
from scipy.spatial.transform import Rotation as R
from sqlalchemy import Column, func, inspect
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from sqlalchemy.schema import ForeignKey
from sqlalchemy.types import Integer, PickleType, String

__all__ = [
    'Image',
]

Base = declarative_base()

MICROSECONDS_IN_A_SECOND = 1000000
LRU_CACHE_SIZE = 20480
LIDAR_BOX_LRU_CACHE_SIZE = 2048

logger = logging.getLogger()


def generate_multi_scale_connections(
    connections: npt.NDArray[np.float64], scales: List[int]
) -> Dict[int, npt.NDArray[np.float64]]:
    """
    Generate multi-scale connections by finding the neighors up to max(scales) hops away for each node.

    :param connections: <np.float: num_connections, 2>. 1-hop connections.
    :param scales: Connections scales to generate.
    :return: Multi-scale connections as a dict of {scale: connections_of_scale}.
    """
    # This dict will have format {node_idx: neighbor_dict},
    # where each neighbor_dict will have format {'i_hop_neighbors': set_of_i_hop_neighbors}.
    node_idx_to_neighbor_dict: Dict[int, Dict[str, Set[int]]] = {}

    # Initialize the data structure for each node with its 1-hop neighbors.
    for connection in connections:
        start_idx, end_idx = list(connection)
        if start_idx not in node_idx_to_neighbor_dict:
            node_idx_to_neighbor_dict[start_idx] = {'1_hop_neighbors': set()}
        if end_idx not in node_idx_to_neighbor_dict:
            node_idx_to_neighbor_dict[end_idx] = {'1_hop_neighbors': set()}
        node_idx_to_neighbor_dict[start_idx]['1_hop_neighbors'].add(end_idx)

    # Find the neighors up to max(scales) hops away for each node.
    for scale in range(2, max(scales) + 1):
        for neighbor_dict in node_idx_to_neighbor_dict.values():
            neighbor_dict[f'{scale}_hop_neighbors'] = set()
            for n_hop_neighbor in neighbor_dict[f'{scale - 1}_hop_neighbors']:
                for n_plus_1_hop_neighbor in node_idx_to_neighbor_dict[n_hop_neighbor]['1_hop_neighbors']:
                    neighbor_dict[f'{scale}_hop_neighbors'].add(n_plus_1_hop_neighbor)

    # Get the connections of each scale.
    multi_scale_connections = {}
    for scale in scales:
        scale_connections = []
        for node_idx, neighbor_dict in node_idx_to_neighbor_dict.items():
            for n_hop_neighbor in neighbor_dict[f'{scale}_hop_neighbors']:
                scale_connections.append([node_idx, n_hop_neighbor])
        multi_scale_connections[scale] = np.array(scale_connections)

    return multi_scale_connections


class Image(Base):
    """
    An image.
    """

    __tablename__ = "image"

    token = Column(sql_types.HexLen8, primary_key=True)  # type: str
    next_token = Column(sql_types.HexLen8, ForeignKey("image.token"), nullable=True)  # type: str
    prev_token = Column(sql_types.HexLen8, ForeignKey("image.token"), nullable=True)  # type: str
    ego_pose_token = Column(sql_types.HexLen8, ForeignKey("ego_pose.token"), nullable=False)  # type: str
    camera_token = Column(sql_types.HexLen8, ForeignKey("camera.token"), nullable=False)  # type: str
    filename_jpg = Column(String(128))  # type: str
    timestamp = Column(Integer)  # type: int

    next = relationship("Image", foreign_keys=[next_token], remote_side=[token])  # type: Image
    prev = relationship("Image", foreign_keys=[prev_token], remote_side=[token])  # type: Image

    @property
    def _session(self) -> Any:
        """
        Get the underlying session.
        :return: The underlying session.
        """
        return inspect(self).session

    def __repr__(self) -> str:
        """
        Return the string representation.
        :return: The string representation.
        """
        desc: str = simple_repr(self)
        return desc

    @property
    def log(self) -> Log:
        """
        Returns the Log containing the image.
        :return: The log containing this image.
        """
        return self.camera.log

    @property
    def scene(self) -> Scene:
        """
        Get the corresponding scene by finding the closest LidarPc by timestamp.
        :return: Scene corresponding to the Image.
        """
        lidar_pc = self._session.query(LidarPc).order_by(func.abs(LidarPc.timestamp - self.timestamp)).first()
        return lidar_pc.scene

    def load_as(self, db: NuPlanDB, img_type: str) -> Any:
        """
        Loads the image as a desired type.
        :param db: Log Database.
        :param img_type: Can be either 'pil' or 'np' or 'cv2'. If the img_type is cv2, the image is returned in BGR
            format, otherwise it is returned in RGB format.
        :return: The image.
        """
        assert img_type in ['pil', 'cv2', 'np']

        pil_img = PIL.Image.open(self.load_bytes_jpg(db))

        if img_type == 'pil':
            return pil_img
        elif img_type == 'np':
            return np.array(pil_img)
        else:
            return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

    @property
    def filename(self) -> str:
        """
        Get the file name.
        :return: The file name.
        """
        return self.filename_jpg

    def load_bytes_jpg(self, db: NuPlanDB) -> BinaryIO:
        """
        Returns the bytes of the jpg data for this image.
        :param db: Log Database.
        :return: The image bytes.
        """
        blob: BinaryIO = db.load_blob(os.path.join("sensor_blobs", self.filename))
        return blob

    @property
    def path(self, db: NuPlanDB) -> str:
        """
        Get the path to image file.
        :param db: Log Database.
        :return: The image file path.
        """
        self.load_bytes_jpg(db)
        return osp.join(db.data_root, self.filename)

    def boxes(self, frame: Frame = Frame.GLOBAL) -> List[Box3D]:
        """
        Loads all boxes associated with this Image record. Boxes are returned in the global frame by default.
        :param frame: Specify the frame in which the boxes will be returned.
        :return: List of boxes.
        """
        boxes: List[Box3D] = get_boxes(self, frame, self.ego_pose.trans_matrix_inv, self.camera.trans_matrix_inv)

        return boxes

    def future_or_past_ego_poses(self, number: int, mode: str, direction: str) -> List[EgoPose]:
        """
        Get n future or past vehicle poses. Note here the frequency of pose differs from frequency of Image.
        :param number: Number of poses to fetch or number of seconds of ego poses to fetch.
        :param mode: Either n_poses or n_seconds.
        :param direction: Future or past ego poses to fetch, could be 'prev' or 'next'.
        :return: List of up to n or n seconds future or past ego poses.
        """

        if direction == 'prev':
            if mode == 'n_poses':
                return (
                    self._session.query(EgoPose)
                    .filter(EgoPose.timestamp < self.ego_pose.timestamp, self.camera.log_token == EgoPose.log_token)
                    .order_by(EgoPose.timestamp.desc())
                    .limit(number)
                    .all()
                )
            elif mode == 'n_seconds':
                return (
                    self._session.query(EgoPose)
                    .filter(
                        EgoPose.timestamp - self.ego_pose.timestamp < 0,
                        EgoPose.timestamp - self.ego_pose.timestamp >= -number * 1e6,
                        self.camera.log_token == EgoPose.log_token,
                    )
                    .order_by(EgoPose.timestamp.desc())
                    .all()
                )
            else:
                raise NotImplementedError('Only n_poses and n_seconds two modes are supported for now!')
        elif direction == 'next':
            if mode == 'n_poses':
                return (
                    self._session.query(EgoPose)
                    .filter(EgoPose.timestamp > self.ego_pose.timestamp, self.camera.log_token == EgoPose.log_token)
                    .order_by(EgoPose.timestamp.asc())
                    .limit(number)
                    .all()
                )
            elif mode == 'n_seconds':
                return (
                    self._session.query(EgoPose)
                    .filter(
                        EgoPose.timestamp - self.ego_pose.timestamp > 0,
                        EgoPose.timestamp - self.ego_pose.timestamp <= number * 1e6,
                        self.camera.log_token == EgoPose.log_token,
                    )
                    .order_by(EgoPose.timestamp.asc())
                    .all()
                )
            else:
                raise NotImplementedError('Only n_poses and n_seconds two modes are supported!')
        else:
            raise ValueError('Only prev and next two directions are supported!')

    def render(
        self, db: NuPlanDB, with_3d_anns: bool = True, box_vis_level: BoxVisibility = BoxVisibility.ANY, ax: Optional[Axes] = None
    ) -> None:
        """
        Render the image with all 3d and 2d annotations.
        :param db: Log Database.
        :param with_3d_anns: Whether you want to render 3D boxes?
        :param box_vis_level: One of the enumerations of <BoxVisibility>.
        :param ax: Axes object or array of Axes objects.
        """

        if ax is None:
            _, ax = plt.subplots(1, 1, figsize=(9, 16))

        ax.imshow(self.load_as(db, img_type='pil'))

        if with_3d_anns:
            for box in self.boxes(Frame.SENSOR):

                # Get the LidarBox record with the same token as box.token
                ann_record = db.lidar_box[box.token]

                c = ann_record.category.color_np
                color = c, c, np.array([0, 0, 0])

                if box_in_image(
                    box, self.camera.intrinsic_np, (self.camera.width, self.camera.height), vis_level=box_vis_level
                ):
                    box.render(ax, view=self.camera.intrinsic_np, normalize=True, colors=color)

        ax.set_xlim(0, self.camera.width)
        ax.set_ylim(self.camera.height, 0)
        ax.set_title(self.camera.channel)
